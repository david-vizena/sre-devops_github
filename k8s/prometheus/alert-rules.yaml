apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  name: portfolio-alerts
  namespace: monitoring
  labels:
    app: portfolio
    prometheus: kube-prometheus
spec:
  groups:
    - name: portfolio.rules
      interval: 30s
      rules:
        # High Error Rate Alert
        - alert: HighErrorRate
          expr: |
            sum(rate(http_requests_total{status=~"5.."}[5m])) by (service) / 
            sum(rate(http_requests_total[5m])) by (service) > 0.05
          for: 5m
          labels:
            severity: critical
          annotations:
            summary: "High error rate detected for {{ $labels.service }}"
            description: "Service {{ $labels.service }} has error rate above 5% for 5 minutes"

        # High Latency Alert
        - alert: HighLatency
          expr: |
            histogram_quantile(0.95, 
              sum(rate(http_request_duration_seconds_bucket[5m])) by (le, service)
            ) > 0.5
          for: 5m
          labels:
            severity: warning
          annotations:
            summary: "High latency detected for {{ $labels.service }}"
            description: "Service {{ $labels.service }} has p95 latency above 500ms for 5 minutes"

        # Service Down Alert
        - alert: ServiceDown
          expr: service_up{service!=""} == 0
          for: 2m
          labels:
            severity: critical
          annotations:
            summary: "Service {{ $labels.service }} is down"
            description: "Service {{ $labels.service }} has been down for 2 minutes"

        # High Memory Usage
        - alert: HighMemoryUsage
          expr: |
            (container_memory_usage_bytes{container!="POD",container!=""} / 
             container_spec_memory_limit_bytes) > 0.9
          for: 5m
          labels:
            severity: warning
          annotations:
            summary: "High memory usage for {{ $labels.container }} in {{ $labels.pod }}"
            description: "Container {{ $labels.container }} is using more than 90% of memory limit"

        # High CPU Usage
        - alert: HighCPUUsage
          expr: |
            rate(container_cpu_usage_seconds_total{container!="POD",container!=""}[5m]) > 0.8
          for: 5m
          labels:
            severity: warning
          annotations:
            summary: "High CPU usage for {{ $labels.container }} in {{ $labels.pod }}"
            description: "Container {{ $labels.container }} is using more than 80% CPU"

        # Pod CrashLooping
        - alert: PodCrashLooping
          expr: |
            rate(kube_pod_container_status_restarts_total[15m]) > 0
          for: 5m
          labels:
            severity: critical
          annotations:
            summary: "Pod {{ $labels.pod }} is crash looping"
            description: "Pod {{ $labels.pod }} has restarted multiple times in the last 15 minutes"

        # SLO Violation - Availability
        - alert: SLOViolationAvailability
          expr: |
            (sum(rate(http_requests_total[24h])) - sum(rate(http_requests_total{status=~"5.."}[24h]))) / 
            sum(rate(http_requests_total[24h])) < 0.999
          for: 1h
          labels:
            severity: critical
          annotations:
            summary: "Availability SLO violation"
            description: "Availability has dropped below 99.9% SLO threshold"

        # SLO Violation - Error Rate
        - alert: SLOViolationErrorRate
          expr: |
            sum(rate(http_requests_total{status=~"5.."}[5m])) / 
            sum(rate(http_requests_total[5m])) > 0.001
          for: 5m
          labels:
            severity: warning
          annotations:
            summary: "Error rate SLO violation"
            description: "Error rate has exceeded 0.1% SLO threshold"

